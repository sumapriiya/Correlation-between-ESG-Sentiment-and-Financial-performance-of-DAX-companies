# -*- coding: utf-8 -*-
"""NER_Company_names.py

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZQ5iqzQVtIc-Nese71V5FC3zNpOZMGmf
"""

import spacy
import pandas as pd
import numpy as np
nlp = spacy.load("en_core_web_sm")

from spacy.matcher import Matcher,PhraseMatcher

## Matching of Concept Forms ###
def search_concept_forms(document,df):
  concept_form_companies = []
  #create a list of companies to match
  
  matching_company = ''
  concept_forms = list(df['concept_forms'])
  
  #Using Token Matcher to find companies ending with AG,SE,Inc,S.A.from the document to be searched for companies 
  #from spacy.matcher import Matcher
  matcher = Matcher(nlp.vocab)

  search_list = []
  
  pattern_0 = [{"IS_ALPHA":True},{"IS_PUNCT": True},{"IS_ALPHA": True}] #S&T
  pattern_1 = [{"IS_ALPHA":True},{"IS_ALPHA": True},{"IS_ALPHA": True} ] #AmadeusFiRe 
  pattern_2 = [{"IS_ALPHA": True},{"IS_ALPHA": True}] #DMGMoriAktiengesellschaft
  
  AG_pattern_0 = [{"IS_ALPHA":True},{"IS_ALPHA": True},{"TEXT": "AG"}]
  AG_pattern_1 = [{"IS_ALPHA":True},{"TEXT": "AG"}]
  AG_pattern_2 = [{"IS_ALPHA":True},{"IS_PUNCT": True},{"IS_ALPHA":True},{"TEXT": "AG"}] #K+SAG, Koenig&BauerAG
  AG_pattern_3 = [{"IS_ALPHA":True},{"IS_ALPHA":True},{"IS_PUNCT": True},{"IS_ALPHA":True},{"TEXT": "AG"},{"IS_ALPHA":True},{"IS_ALPHA":True}]    #MuenchenerRueckversicherungs-GesellschaftAGinMuenchen
  AG_pattern_4 = [{"IS_ALPHA":True},{"IS_ALPHA":True},{"IS_ALPHA":True},{"IS_PUNCT": True},{"TEXT": "AG"}] # alstriaofficeREIT-AG
  AG_pattern_5 = [{"IS_ALPHA":True},{"IS_ALPHA":True},{"IS_ALPHA":True},{"TEXT": "AG"}] #TelefรณnicaDeutschlandHoldingAG
  AG_pattern_6 = [{"TEXT": "Dr."},{"IS_ALPHA":True},{"TEXT": "AG"}]#Dr.HönleAG
  AG_pattern_7 = [{"IS_ALPHA":True},{"IS_PUNCT": True},{"IS_ALPHA":True},{"IS_ALPHA":True},{"IS_PUNCT": True},{"IS_ALPHA":True},{"IS_ALPHA":True},{"TEXT": "AG"}]  # Eckert&ZieglerStrahlen-undMedizintechnikAG
  AG_pattern_8 = [{"IS_ALPHA":True},{"IS_ALPHA":True},{"IS_PUNCT":True},{"IS_ALPHA": True},{"TEXT": "AG"}]#LPKFLaser&ElectronicsAG
  AG_pattern_9 = [{"IS_ALPHA":True},{"IS_PUNCT":True},{"IS_ALPHA": True},{"TEXT": "AG"}]#Wüstenrot&WürttembergischeAG
  
  SE_pattern_0 = [{"IS_ALPHA":True},{"TEXT": "SE"}]
  SE_pattern_1 = [{"IS_ALPHA":True},{"IS_ALPHA":True},{"IS_ALPHA":True},{"IS_PUNCT":True},{"IS_DIGIT":True},{"IS_ALPHA":True},{"TEXT": "SE"}] #ProSiebenSat.1MediaSE
  SE_pattern_2 = [{"IS_ALPHA":True},{"IS_PUNCT":True},{"TEXT": "CoSE"}]#Klöckner&CoSE
  SE_pattern_3 = [{"IS_ALPHA":True},{"IS_ALPHA":True},{"IS_PUNCT":True},{"IS_ALPHA":True},{"IS_PUNCT":True},{"IS_ALPHA":True},{"TEXT": "SE"}]#SNPSchneider-Neureither&PartnerSE
  SE_pattern_4 = [{"IS_ALPHA":True},{"IS_ALPHA":True},{"IS_ALPHA":True},{"TEXT": "SE"}]#PorscheAutomobilHoldingSE
  
  Inc_pattern = [{"IS_ALPHA":True},{"TEXT": "Inc"}]
  SA_pattern_0 = [{"IS_ALPHA":True},{"TEXT": "S.A."}]
  SA_pattern_1 = [{"IS_ALPHA":True},{"IS_ALPHA":True},{"IS_ALPHA":True},{"TEXT": "S.A."}]#CorestateCapitalHoldingS.A.
  SA_pattern_2 = [{"IS_ALPHA":True},{"IS_PUNCT":True},{"IS_ALPHA":True},{"TEXT": "S.A."}]#SAF-HollandS.A.
  
  Co_pattern_0 = [{"IS_ALPHA":True},{"IS_ALPHA":True},{"IS_ALPHA":True},{"TEXT": "AG"},{"IS_PUNCT": True},{"TEXT": "CoKGaA"}]      #FreseniusMedicalCareAG&CoKGaA
  Co_pattern_1 = [{"IS_ALPHA":True},{"TEXT": "SE"},{"IS_PUNCT": True},{"TEXT": "CoKGaA"}] #FreseniusSE&CoKGaA
  Co_pattern_2 = [{"IS_ALPHA":True},{"TEXT": "AG"},{"IS_PUNCT": True},{"TEXT": "CoKGaA"}] #Henkel
  Co_pattern_3 = [{"IS_ALPHA":True},{"IS_ALPHA":True},{"TEXT": "AG"},{"IS_PUNCT": True},{"TEXT": "Co.KGaA"}] #CTSEventimAG&Co.KGaA
  Co_pattern_4 = [{"IS_ALPHA":True},{"TEXT": "GmbH"},{"IS_PUNCT": True},{"TEXT": "Co.KGaA"}] #HELLAGmbH&Co.KGaA
  Co_pattern_5 = [{"IS_ALPHA":True},{"TEXT": "SE"},{"IS_PUNCT": True},{"TEXT": "Co.KGaA"}]#StrรถerSE&Co.KGaA
  Co_pattern_6 = [{"IS_ALPHA":True},{"IS_ALPHA":True},{"TEXT": "GmbH"},{"IS_PUNCT": True},{"TEXT": "Co.KGaA"}] #BorussiaDortmundGmbH&Co.KGaA and DWSGroupGmbH&Co.KGaA
  Co_pattern_7 = [{"IS_ALPHA":True},{"IS_ALPHA":True},{"IS_PUNCT": True},{"TEXT": "Co.KGaA"}]  #CeweStiftung&Co.KGaA
  Co_pattern_8 = [{"IS_ALPHA":True},{"IS_PUNCT": True},{"TEXT": "Co.KGaA"}] #KWSAATSE&Co.KGaA
  
  KG_pattern_0 = [{"IS_ALPHA":True},{"TEXT": "KGaA"}] #Merck
  
  NV_pattern_0 = [{"IS_ALPHA":True},{"TEXT": "N.V."}] #QiagenN.V.
  NV_pattern_1 = [{"IS_ALPHA":True},{"IS_ALPHA":True},{"IS_ALPHA":True},{"TEXT": "N.V."}]#SteinhoffInternationalHoldingsN.V.
  
  matcher.add("pat0",[pattern_0])
  matcher.add("pat1",[pattern_0])
  matcher.add("pat2",[pattern_0])
  matcher.add("AG0",[AG_pattern_0])
  matcher.add("AG1", [AG_pattern_1])
  matcher.add("AG2", [AG_pattern_2])
  matcher.add("AG3", [AG_pattern_3])
  matcher.add("AG4", [AG_pattern_4])
  matcher.add("AG5", [AG_pattern_5])
  matcher.add("AG6", [AG_pattern_6])
  matcher.add("AG7", [AG_pattern_7])
  matcher.add("AG8", [AG_pattern_8])
  matcher.add("AG9", [AG_pattern_9])
  matcher.add("SE0", [SE_pattern_0])
  matcher.add("SE1", [SE_pattern_1])
  matcher.add("SE2", [SE_pattern_2])
  matcher.add("SE3", [SE_pattern_3])
  matcher.add("SE4", [SE_pattern_4])
  matcher.add("Inc", [Inc_pattern])
  matcher.add("SA0", [SA_pattern_0])
  matcher.add("SA1", [SA_pattern_1])
  matcher.add("SA2", [SA_pattern_2])
  matcher.add("Co0",[Co_pattern_0])
  matcher.add("Co1",[Co_pattern_1])
  matcher.add("Co2",[Co_pattern_2])
  matcher.add("Co3",[Co_pattern_3])
  matcher.add("Co4",[Co_pattern_4])
  matcher.add("Co5",[Co_pattern_5])
  matcher.add("Co6",[Co_pattern_6])
  matcher.add("Co7",[Co_pattern_7])
  matcher.add("Co8",[Co_pattern_8])
  matcher.add("KG0",[KG_pattern_0])
  matcher.add("NV0",[NV_pattern_0])
  matcher.add("NV1",[NV_pattern_1])
  
  doc = nlp(document)
  matches = matcher(doc)
  for match_id, start, end in matches:
    search_str = doc[start:end].text
    search_str = search_str.replace(' ', '')
    search_list.append(search_str) 
  
  #search in DAX companies list, if there is a match from the above list

  #from spacy.matcher import PhraseMatcher
  matcher = PhraseMatcher(nlp.vocab)

  #obtain doc object for each word in the list and store it in a list
  patterns = [nlp(company) for company in concept_forms]
            
  #add the pattern to the matcher
  matcher.add(str(search_list), patterns)

  #process some text
  doc = nlp(str(search_list))
  matches = matcher(doc)

  for match_id, start, end in matches:
    span = doc[start:end]
    matching_company=span.text
    concept_form_companies.append(matching_company)
      
  #check for other names present(the most normal forms) without extension
  #from spacy.matcher import PhraseMatcher

  matcher = PhraseMatcher(nlp.vocab)

  #obtain doc object for each word in the list and store it in a list
  patterns = [nlp(company) for company in concept_forms]
            
  #add the pattern to the matcher
  matcher.add(document, patterns)

  #process some text
  doc = nlp(document)
  matches = matcher(doc)

  for match_id, start, end in matches:
    span = doc[start:end]
    matching_company=span.text
    concept_form_companies.append(matching_company) 
 
  return concept_form_companies

## Matching of Surface forms ##
def search_surface_forms(document,df):
  surface_form_companies = []
  surface_forms = []
 
  matching_company = ''
  #create a list of companies to match
  surface_forms_list = list(df['surface_forms_en'])

  #Split at the comma, to get the individual company names
 
  for item in surface_forms_list: 
    split_str = item.split(',')
    for each_string in split_str: 
      surface_forms.append(each_string)
  #print(surface_forms)    
  #Using Token Matcher to find companies 
  #from spacy.matcher import Matcher
  matcher = Matcher(nlp.vocab)

  search_list = []

  pattern_0 = [{"IS_ALPHA":True}]
  pattern_1 = [{"IS_ALPHA":True},{"IS_ALPHA": True}]
  pattern_2 = [{"IS_ALPHA":True},{"IS_ALPHA": True},{"IS_ALPHA": True}]
  pattern_3 = [{"IS_DIGIT":True},{'IS_PUNCT': True},{"IS_DIGIT": True}]
  pattern_4 = [{"IS_DIGIT":True},{'IS_PUNCT': True},{"IS_DIGIT": True},{'IS_PUNCT': True},{"IS_DIGIT": True}]
  
  matcher.add("pat_0", [pattern_0])
  matcher.add("pat_1", [pattern_1])
  matcher.add("pat_2", [pattern_2])
  matcher.add("pat_3", [pattern_3])
  matcher.add("pat_4", [pattern_4])
  
  doc = nlp(document)
  matches = matcher(doc)
  for match_id, start, end in matches:
    search_str = doc[start:end].text
    search_str = search_str.replace(' ', '_')
    search_list.append(search_str)
  
  #print(search_list)
  #Now check if these names exist in the surface_forms list
  #from spacy.matcher import PhraseMatcher

  matcher = PhraseMatcher(nlp.vocab)

  #obtain doc object for each word in the list and store it in a list
  patterns = [nlp(company) for company in surface_forms]
            
  #add the pattern to the matcher
  matcher.add(str(search_list), patterns)

  #process some text
  doc = nlp(str(search_list))
  matches = matcher(doc)

  for match_id, start, end in matches:
    span = doc[start:end]
    matching_company=span.text  
    surface_form_companies.append(matching_company)

  return surface_form_companies

## Matching of Ambiguous surface forms ##
def search_ambiguous_forms(document,df): 
  amb_form_companies = []

  matching_company = ''
  ambiguous_forms = []
  ambiguous_surface_forms_list = list(df['ambiguous_surface_forms_en'])
  ambiguous_surface_forms = []
  
  for item in ambiguous_surface_forms_list:
    if(pd.isna(item) == False): 
      ambiguous_surface_forms.append(item)

  # now include the ambiguous forms only if it's present in concept forms or surface forms 
 # for item in ambiguous_surface_forms:
 #   if (item in surface_forms) or (item in concept_forms):
 #     ambiguous_forms.append(item)

  #Now check if these names exist in the ambiguous_surface_forms list
  #from spacy.matcher import PhraseMatcher

  matcher = PhraseMatcher(nlp.vocab)

  #obtain doc object for each word in the list and store it in a list
  patterns = [nlp(company) for company in ambiguous_forms]
            
  #add the pattern to the matcher
  matcher.add(document, patterns)

  #process some text
  doc = nlp(document)
  matches = matcher(doc)

  for match_id, start, end in matches:
    span = doc[start:end]
    matching_company=span.text
    amb_form_companies.append(matching_company)

  return amb_form_companies
    
 